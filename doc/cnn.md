# [QuNet](README.md) - CNN

## Введение

В библиотеке  [QuNet](README.md) различные  архитетектуры с конволюционными 2d слоями создаются при помощи класса `CNN`.
Основным параметром его конструктора является строка `blocks`. 
Она состоит из разделённых пробелами "токенов" определяющих последовательность элементарных или составных слоёв сети.
Например, сеть resnet18 создаётся следующим образом:
```python
cnn = CNN(input=3, blocks="(c64_7_2 n f  m3_2) 2r r128_3_2 r r256_3_2 r r512_3_2 r")
```
В круглых скобках (которые играют  роль группировки) находится последовательность элементарных слоёв:
* `c64_7_2` - это конволюция `Conv2d` в 64 канала с ядром 7 и шагом 2. 
* `n` - нормализационный слой, равный по умолчанию  `BatchNorm2d`.
* `f` - активационная функция  (по умолчанию это `relu`).
* `m3_2` - это `MaxPool2d` с ядром 3 и шагом 2.

Затем идут составные блоки.

Токен `2r` означает, что идёт последовательность двух одинаковых residual блоков `r`.
Каждый из них содержит по два конволюционных слоя с нормировкой и нелинейностю между ними. Они окружены петлёй skip-connection. Такие блоки не меняют размерности тензора.

Токен `r128_3_2` также является residual блоком. Первый его конволюционный слой увеличивает число каналов до 128 и благодаря шагу (stride=2) уменьшает в 2 раза высоту H и ширину W входного тензора `(B,C,H,W)`. Второй конволюционный слой блока также имеет 128 выходных каналов, ядро 3 и уже единичный страйд. 
Так как размерность тензора меняется: `(B,64,H,W) -> (B,128,H/2,W/2)`, то петля skip-connection содержит  конволюционный слой `Conv2d(64,128,1)`, который выравнивает размерности входного и входного тензоров.

Аналогичный смысл имеют остальные токены строки.  Параметр `input` задаёт число входных каналов изображения.

Полная модель, решающая задачу классификации на основе архитектуры resnet18, должна дополнительно содержать классификатор (токен `cnf` это объединение последовательности `c n f`):
```python
m = nn.Sequential(
    CNN(input=3, avg=True, flat=True,
        blocks="(cnf64_7_2  m3_2) 2r r128_3_2 r r256_3_2 r r512_3_2 r"),    
    MLP(input=512, output=10) )
```
Параметр `avg=True` означает добавление после blocks слоя  `AdaptiveAvgPool2d(1)`,
а параметр `flat=True` добавление `Flatten()`. На самом деле их указывать не обязательно, т.к. их значение по умолчанию равно `True`.

<hr>

## Элементарные слои

Главный элементарный токен, это токен конволюционного слоя `c[channels]_[kernel]_[stride]_[padding]`.
По умолчанию число выходных каналов `channels` равно числу входных каналов, ядро `kernel=3` и шаг `stride=1`.
Если `padding` не задан (так обычно будет для resnet-овских архитектур), то он принимается равным `padding = (kernel - 1) // 2`. Таким образом:
```
c64      - Conv2d(..., 64, kernel_size=3, padding=1)
c64_5    - Conv2d(..., 64, kernel_size=5, padding=2)
c64_7_2  - Conv2d(..., 64, kernel_size=7, padding=3, stride=2)
```
Обратим внимание, что если `kernel=3`, а `stride=2`, то для однозначности нужно указать оба параметра: `c64_3_2`, хотя по умолчанию `kernel=3`.

Токен нормировки слоя это просто символ `n` или `n1`, `n2`, `n3`, где число означает тип нормировочного слоя (см. ниже раздел "Нормализация").

Токен  `f` - функция активации (по умолчнию это `relu`, см раздел ниже "Активационная функция")

Ещё два токена `m` и `a` создают слои `MaxPool2d` и `AvgPool2d` соответственно. 
Они имеют параметры `m[kernel]_[stride]_[padding]`, со значениями по умолчанию:
`kernel=2`, `stride=2`, `padding=0`. 
Поэтому одиночный символ `m` уменьшит размеры изображения в два раза.

Пару пробелов можно сэкономить при помощи токена `cnf`, который означает последовательность трёх слоёв `"c n f"`, где, идущие после него параметры относятся к конволюционному слою.

Токен `d` - означает слой Dropout. По умолчанию это `Dropout2d`, что задаётся аргументом консруктора `drop_d=2`. 
В конкретном месте можно изменить размерность дропаута, поставив `d1` для `Dropout`  и `d2` для `Dropout2d`.
Вероятность дропаута при его создании всегда равна 0. (т.е. слои фактически не работают)
Чтобы их активировать, необходимо подключить класс `Change` и, после создания модели, вызвать его статический метод `dropout`.
Ему первым параметром передаётся модель (или часть её), а вторым  - значение вероятности `p`.
Если это число, то для всех слоёв `DropoutXd` будет задано это значение. 
Можно также задать масив вещественных чисел по числу слоёв `DropoutXd`.
Если этот массив коороче, чем число слоёв, будет повторяться последнее значение в массиве.

Общие параметры конструктора, влияющие на элементарные слои (приведены значения по умолчанию):

```python
bias   = False,         # создавать ли слои Conv2d со смещением
norm   = 1,             # тип нормировки для токенов 'n'
drop_d = 2,             # размерность Dropout для токенов `d` 
fun    = 'relu',        # активационная функция для токена `f`
```

Пример:
```python
from qunet import CNN, Change, ModelState

cfg = Config(
    input=1,                        # число каналов на входе
    fun = 'gelu',                   # меняем активацию с relu на gelu
    blocks="cnf32 m d cnf64 m d")   # собственно определяем архитектуру

m = CNN(cfg)  
Change.dropout(m, [0.1, 0.2])

s = ModelState(m)
s.layers(2, input_size=(1,1,28,28) )
```
Класс `ModelState` выдаст следующую структуру сети (естественно всегда рекомендуется её просматривать):
```
CNN:  (1, 1, 28, 28) -> (1, 64)                           
CNN                                       params           input -> output shapes            
├─ ModuleList                                                              ->                
│  └─ Sequential                                           (1, 1, 28, 28)  -> (1, 32, 28, 28)
│     └─ Conv2d(1->32, k:3, s:1, p:1, F)     288  ~   2% | (1, 1, 28, 28)  -> (1, 32, 28, 28)
│     └─ BatchNorm2d(32)                      64         | (1, 32, 28, 28) -> (1, 32, 28, 28)
│     └─ GELU                                              (1, 32, 28, 28) -> (1, 32, 28, 28)
│  └─ MaxPool2d(k:2, s:2, p:0)                             (1, 32, 28, 28) -> (1, 32, 14, 14)
│  └─ Dropout2d(0.1)                                       (1, 32, 14, 14) -> (1, 32, 14, 14)
│  └─ Sequential                                           (1, 32, 14, 14) -> (1, 64, 14, 14)
│     └─ Conv2d(32->64, k:3, s:1, p:1, F) 18,432  ~  97% | (1, 32, 14, 14) -> (1, 64, 14, 14)
│     └─ BatchNorm2d(64)                     128  ~   1% | (1, 64, 14, 14) -> (1, 64, 14, 14)
│     └─ GELU                                              (1, 64, 14, 14) -> (1, 64, 14, 14)
│  └─ MaxPool2d(k:2, s:2, p:0)                             (1, 64, 14, 14) -> (1, 64, 7, 7)  
│  └─ Dropout2d(0.2)                                       (1, 64, 7, 7)   -> (1, 64, 7, 7)  
│  └─ AdaptiveAvgPool2d(1)                                 (1, 64, 7, 7)   -> (1, 64, 1, 1)  
│  └─ Flatten                                              (1, 64, 1, 1)   -> (1, 64)        
```

Если `ModelState` вылетает при выводе слоёв layers, стоит его запустить без парметра `input_size`.
Например, возможно указано неверное число входных каналов `input` или размер входного изображения меньше, 
чем число понижающих размер изображения блоков. Ну и наконец, никто не отменял старого доброго `print(m)`.
<hr>

## Residual Block

Токен `r` или `r[channels]_[kernel]_[stride]` создаёт блок с петлёй обхода (skip-connection).
В общем случае этот блок выглядит следующим образом:

<center>
<img src="img/resblock.png" style="width:800px"> 
</center>

Центральным преобразователем входного тензора является `block(x)`. 
Он состоит из двух конволюционных слоёв с нормировкой и нелинейностью между ними.
Если stride отличен от единицы, то возможны два варианта. 
По умолчанию (`cfg.stride_first=True`) в первом слое стоит `stride > 1`, а во втором `stride=1`.
Если же `cfg.stride_first=False`,  то наоборот:

```python
Conv2d(...,     channels, kern, stride)  |  Conv2d(...,     channels, kern,  1)
Norm(channels)                           |  Norm(channels)                     <- cfg.norm_inside
ReLU()                                   |  ReLU()
Conv2d(channels, channels, kern, 1)      |  Conv2d(channels, channels, kern, stride)
Norm(channels)                           |  Norm(channels)                     <- cfg.norm_last
```

В обоих случаях размер изображения уменьшается в 2 раза. Вариант по умолчанию принят resnetXX архитектурах.
При одинаковом числе параметров `cfg.stride_first=True`  работает быстрее (сразу изображение уменьшает), но может оказаться менее эффективным (второе преобразование над меньшим тензором).
Тип нормировки, определяется параметром `cfg.norm_inside=1`, а функция активации параметром `cfg.fun_inside="relu"`.

В простейшем случае (`r` без параметров) размерности тензора на входе и на выходе совпадают (не меняется, ни число каналов, ни размер изображения). Такой блок окружается простой петлёй `align(x) = x`.

Если размерности тензора на входе и на выхде не совпадают (`channels` отлично от числа входных каналов  или `stride > 1`),
то петля `align(x)` является конволюционным слоём, который выравнивает размерности:
```
Con2d(...,  channels, kern, stride)
Norm(channels)                        <- cfg.norm_align
```

В наличие и  порядок выполнения нормировок пределяется следующими настройками:
```python
norm_before   = 0,      # тип нормировки перед блоком block(x)
norm_inside   = 1,      # тип нормировки внутри блока block(x) между Conv2d
norm_last     = 1,      # тип нормировки внутри блока block(x) после последнего Conv2d
norm_align    = 1,      # тип нормировки внутри блока align(x) после Conv2d
norm_after    = 0,      # добавлять нормировку после блоков ('r')
```

Свойства множителя `gamma` определяется конфигом. По умолчанию  (`cfg.res=1`) это единичная константа.
При `cfg.res=2` - обучаемый скалярный параметр и `cfg.res=3`  обучаемый вектор  размерности `С` (по числу каналов).
```python
stride_first  = True,   # делать stride>1 на первом Conv2d, иначе на последнем
drop_d_inside = 0,      # тип Dropout между Conv2d в блоках ('r', 'b')
fun_inside    = 'relu', # активационная функция для блоков ('r')
            
res           = 1,      # тип gamma (1-константа, 2-обучаемое число, 3-обучаемый вектор)
gamma         = 0.,     # начальное значение gamma (для res > 1)
```

После вычисления `align(x) + gamma * block( norm(x) )` может стоять нормировка, функция активации и дроаут.
Это регулируется параметрами конфига:
```python
norm_after    = 0,      # добавлять нормировку после блоков ('r')
fun_after     = "",     # добавлять активационную функцию после блоков ('r')
drop_d_after  = 2,      # тип Dropout после блоков ('r')
```


Сам по себе блок `block(x)` (без петли) можно добавить при помощи токена `b`.

<hr>

## Нормализация

Нормализационный слой на входе получает тензор `x = (B,C,H,W)` и возвращает его 
в нормализованном  виде при помощи его среднего и стандарного отклонения от среднего:
```python
x = ( (x-x.mean(dims))/x.std(dims) ) * alpha + beta
```
где `alpha`, `beta` обучаемые векторы размерности `C`, т.е. слой имеет `2*C` параметров требующих градиента (в начале обучения `alpha=1`, `beta=0`).
Во всех случаях `alpha, beta` имеют форму `(1,C,1,1)`, а при вычислении средних стоит флаг `keepdims=True`.
Размерности `dims` по которым происходит усреднение, зависят от типа номализационного слоя (параметр `norm` в cfg ResCNN):

* `norm = 1` - nn.**BatchNorm2d**(C) - среднее по батчу (`dims=B`). Такая нормировка  вычисляет средние значения яркости каждого пикселя по всем примерам батча в каждом канале.  Дополнительно этот слой сохраняет скользящие средние mean и std, которые затем используются в режиме `eval` даже если пример в батче один.
* `norm = 2` - **LayerNormChannels**(C) - среднее по каналам (`dims=C`). Эта нормировка рассматривет индекс `C` как индекс вектора признаков (каким он и является в конечном итоге). Среднее значение этого вектора делается нулевым, а std - единичным. Затем обычаемые константы его именяют различным образом для каждой компоненты вектора.
* `norm = 3` - nn.**InstanceNorm2d**(C) - среднее по изображению (`dims=H,W`). В этом случае для каждого примера и канала усредняются яроксти всех пикселей. Нормированные изображения подправляются константтами `alpha` и `beta` имеющих уникальные значения для каждого канала (но общие для всех пикселей и примеров)

Для всех блоков используется один и тот же активационный слой, определяемый параметром `cfg.norm=1`.
Он же будет поставлен на место буквы `n` при описании архитектуры.
После буквы `n` можно поставить номер нормализатора. В этом случае он изменится от значения по умолчанию.
```python
"c32 n"  # после конволюции будет нормализационный слой cfg.norm
"c32 n2" # после конволюции будет LayerNormChannels, независимо от значения cfg.norm
```

<hr>

## Активационная функция

Этот параметр является строкой, которая может принимать следующие значения:
```python
'relu', 'gelu', 'relu6', 'sigmoid', 'tanh', 'swish', 'hswish', 'hsigmoid'
```
Как и в случае нормализции функция задается единым параметром `cfg.fun="relu"` для всех блоков.
Однако, при желании, её можно указать явным образом со значением отличным от значения по умолчанию:
```python
"r n f"     # на место f будет поставлена активационная функция из cfg.fun
"r n gelu"  # независимо от cfg.fun тут будет использоваться функция GELU
```

<hr>

## Визуализация

Класс `ModelState` для визуализации глубоких cnn-подобных архитектур не всегда удобен, т.к. они содержать большое число  параметров. Поэтому имеет смысл дополнительно запускать визуализацию CNN. Для этого необходимо перевести модель в режим отладки (`debug`).
В этом режиме вычисляются абсолютные средние значения входого в residual block тензора и аналогичное значение после  `block(x)`.
Их отношения `block( norm(x) ) / align(x)` для каждого блока показывается на графике в как бары. 
Чем это отношение больше, тем "активнее" работает преобразователь `block(x)`. 
Если же он "отстаёт в обучении", то сети выгоднее "загнать" его выход в ноль, чтобы он "не мешал" входным фичам 
(при этом блок фактически не работает).

```python
state = ModelState(model)
model.cnn.debug(True)

trainer.fit(epochs=300, states=[model.cnn,  state], period_state=10, period_plot=10)
```

Рассмотрим в качестве примера `resnet18 = (cnf64 m) 2r r128_3_2 r r256_3_2 r r512_3_2 r`, адаптированную под датасет CIFAR10. После 300 эпох с lr=1e-3 и batch_size=100, валиационная точночность достигает значения 0.932. 
График "обученности" блоков имеет вид:

<center>
<img src="img/resnet18_v1a.png" style="width:950px">
</center>

Видно, что последний блок `r` не добавляет новой информации к признакам (причина обсуждается в последнем разделе). 
Устранение этого блока уменьшает число параметров на 42% (с 11,117k до 6,453k). 
Время обучение (trn) на 1e6 примеров снижается на 20% (с 553s до 442s).
При этом кривая обучения, лишь чуть ниже исходной (которая на графике приведена полупрозрачной линией):

<center>
<img src="img/resnet18_v2.png" style="width:950px">
</center>

Если при создании сети, положить `res=2,  gamma=1.` (обучаемый множитель `align(x) + gamma * block(x)`), то на графике визуализации сплошной линией отражается значение `gamma` для каждого блока, а пунктиром - модуль градиента по `gamma`:

<center>
<img src="img/resnet18_v3a.png" style="width:950px">
</center>

<hr>

## Варианты CNN-архитектуры

При построении CNN-архитектуры необходимо учитывать размер входного тензора и желаемое число признаков на выходе сети (число каналов в последем слое `AdaptiveAvgPool2d`).
Кроме этого ширина и высота финального тезора (перед `AdaptiveAvgPool2d`) не должна быть слишком большой или слишком маленькой (1x1). В первом случае признаки будут по-прежнему фокусироваться на мелких деталях. Во втором вычисления последних конволюционных блоков может быть не эффективно. Например, если на вход конволюции с ядром 3 и паддингом 1 поступает тензор `(512,2,2)`, то в каждом "пикселе" при вычислении будет участвовать все 4 значимых пикселя и 5 нулей паддинга. Возможно в этом случае имеет смысл раньше вызвать `AdaptiveAvgPool2d` и добавить скрытый слой в классификаторе.

Хорошие готовые архитектуры иногда необходимо адаптировать под конкретную задачу. 
Напимер к CIFAR10 с изображениями `(3,32,32)` не подходит resnet18, у которой в самом первом слое происходит уменьшение изображения в 4: `(cnf64_7_2 m3_2)` - сначала конволюция с ядром 7 и страйдом 2, затем MaxPooling с ядром 3. Такая архитектура приведёт к ошибке (размер изображения станет меньше чем 1x1). Для этой задачи целесообразно изменить начало сети, например, на `(cnf64 m)`.


В residual архитектуре важную роль играет наличие и  порядок выполнения нормировок.
Например, в блоке с нетривиальным `align(x)` должен быть `norm(x)` на входе `align` и на выходе `block(x)` (т.е. `сfg.norm_last`),
чтобы оба слагаемых в сумме `align(x) + block(x)` имели одинаковое (нулевое) среднее. Не выполнение этого условия может привести к потере 1-2% точности и разболансировке dx/x на столбиках визуализации.

Ключевым действием в CNN архитектуре - это увеличение числа каналов и уменьшение ширины и высоты тензора.
В качестве примера будем считать, что текущее число каналов равно 32 и мы хотим уменьшить объем тезора `(32, H, W)` в два раза, получив `(64, H/2, W/2)`. Возможны следующие варианы как это можно сделать при  помощи res-блоков. 

* `"r64_3_2",  cfg.stride_first=True` - это типичный для resnetXX способ уменьшения размера при помощи страйда в первой конволюции. Этот способ наиболее экономный (первый слой формирует уменьшенный тензор и второй слой его преобразует).
* `"r64_3_2",  cfg.stride_first=False` - в этом случае уменьшение объёма произойдёт после второго слоя, тогда как первый его объём в 2 раза увелчит (число каналов).
* `"r64 m"` - самый затратный, но эффективный способ преобразования при котором сначала увеличивается число каналов, происходит их обработка во втором слое, а умменьшение размеров осуществляется при помощи MaxPooling.

Какой из этих способов окажется лучше, конечно, вопрос эксппериментальный. 
Ниже приведен график кривой обучения для третьего варианта 
```
r64 m r r128 m r r256 m r r512 m
``` 
При том что он содердит почти в 2 раза меньше параметров, чем адаптированный для CIFAR10 resnet18, эта модель  опережает resnet18 (полупрозрачные линии) на более чем 2%. 
Хотя это и происходит за счёт увеличения времени тренировки на 20% (при тех же параметрах).

<center>
<img src="img/22_(r64 m r r128 m r r256 m r r512 m)_res1.png" style="width:950px">
</center>

Естественно, при сильной агументации, для архитектур с residual blocks, чем больше параметров, тем лучше.
Ниже приведены валидационные точности и время тренировки на 1e6 примеров для  трёх одинаковых архитектур после 300 эпох:
```
acc        time      pars      blocks
0.9305     295s     1,608k     r32  m r r64  m r r128 m r r256  m
0.9461     512s     6,417k     r64  m r r128 m r r256 m r r512  m
0.9648   1,292s    25,632k     r128 m r r256 m r r512 m r r1024 m
```

Возможно полезной эвристикой является анализ издержек вычислений на каждом блоке и изменение (обычно уменьшение) объёма тензора на его выходе по сравнению с исходным тензором (для CIFAR10 `V0=3*32*32`):
```
               (cnf64 m)      2r  r128_3_2     r  r256_3_2      r  r512_3_2     r
----------------------------------------------------------------------------------            
pars 11,165           2     2*74       230   295      919   1,180   3,672   4,720
ops     140         1.8     2*19        15    19       15      19      15      19
w        32          16       16         8     8        4       4       2       2
V0/V    1.5         0.2      0.2       0.4   0.4      0.8     0.8     1.5     1.5

                    r64       m       r128     m     r256       m      r512     m
----------------------------------------------------------------------------------
pars  4860           39                230            919              3672   
ops    216           40                 59             59                59
w       32           32      16         16     8        8       4         4     2
V0/V   1.5         0.05     0.2        0.1   0.4      0.2     0.8       0.4   1.5
```

В этом документе для всех примеров с CIFAR10 использовались одинаковые гиперпараметры: `lr=1e-3, batch_size=100, Adam` и следующие преобразования агументации из torchvision:
```python
class Transform(Callback):
    def __init__(self):
        self.transform = transforms.Compose([    
            TrivialAugmentWide(interpolation=transforms.InterpolationMode.BILINEAR),
            RandomHorizontalFlip(),
            RandomCrop(32, padding=4),            
            RandomErasing(p=0.1),                   
            Lambda(lambda x: (x/255.0).float()),
            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], True)])

    def on_train_after_batch_transfer(self, trainer, model, batch, batch_id): #GPU
        batch[0] = self.transform(batch[0])
        return batch
```